{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to PySpark\n",
    "\n",
    "**Course Structure:**\n",
    "* Chapter 1. Getting to know PySpark\n",
    "* Chapter 2. Manipulating data\n",
    "* Chapter 3. Getting started with machine learning pipelines\n",
    "* Chapter 4. Model tuning and selection\n",
    "\n",
    "### CHAPTER 1. Getting to know PySpark\n",
    "\n",
    "#### Part 1.1 What is Spark\n",
    "\n",
    "* It is a platform for cluster computing\n",
    "* It allows you to spread adta and computations over clusters with multiple nodes (separate computers)\n",
    "* Makes it easier to work with large datasets\n",
    "* Each node works on its own subset of the total data and part of total calculations\n",
    "\n",
    "**Key considerations:**\n",
    "* Is my data too big to work with on a single machine?\n",
    "* Can my calculations be easily parallelized?\n",
    "\n",
    "**Using Spark in Python:**\n",
    "* The first step is connecting to a cluster (a remote machine connected to all other nodes)\n",
    "* One computer called the *master* that manages to split up data and computations\n",
    "* Creating connection by creating an instance of *'SparkContext'* class\n",
    "* An object holding all attributes can be created with *'SparkConf()'* constructor\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "991fb6a196e56572"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\JAVA\\jdk-21.0.0\n",
      "E:\\SPARK\\spark-3.5.0-bin-hadoop3\\spark-3.5.0-bin-hadoop3\n"
     ]
    }
   ],
   "source": [
    "# launch Spark server with Spark Connect\n",
    "# !$HOME/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:$SPARK_VERSION\n",
    "\n",
    "# check for 'JAVA_HOME' variable setting\n",
    "import os\n",
    "import sys\n",
    "\n",
    "java_home = os.environ.get(\"JAVA_HOME\")\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "print(java_home)\n",
    "print(spark_home)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:35:35.682461Z",
     "start_time": "2023-11-20T04:35:35.530591800Z"
    }
   },
   "id": "d3e7f206ddf446dd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local appName=Spark Example App>\n",
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Code for part 1.1 \n",
    "\n",
    "# examining the Spark context\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# create the Spark context\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Spark Example App\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "print(sc)\n",
    "print(sc.version)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:19.620992400Z",
     "start_time": "2023-11-20T04:35:35.685453200Z"
    }
   },
   "id": "4afe59acd7c7561a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 1.2 Using DataFrames\n",
    "\n",
    "* Spark's core data structure is the **Resilient-Distributed Dataset (RDD)**\n",
    "* Spark DataFrame is built on top of RDDs\n",
    "* It is designed to behave like a SQL table\n",
    "* First, you have to create a *'SparkSession'* object from *'SparkContext'*\n",
    "* *'SparkContext'* is the connection to the cluster\n",
    "* *'SparkSession'* is the interface with the connection\n",
    "* NOTE: Since PySpark 2.0, creating a **SparkSession** creates a **SparkContext** internally and exposes the **SparkContext** variable to use"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e55bb84898e36446"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001B318403B10>\n",
      "[Table(name='flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Code for part 1.2\n",
    "\n",
    "# creating a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# create my_spark\n",
    "my_spark = SparkSession.builder.appName(\"Spark Example\").getOrCreate()\n",
    "print(my_spark)\n",
    "\n",
    "# get data into tables for my_spark: 'flights'\n",
    "path = '21_datasets/flights.csv'\n",
    "flights_df = my_spark.read.csv(path, header=True, inferSchema=True)\n",
    "tableName = 'flights'\n",
    "flights_df.createOrReplaceTempView(tableName)\n",
    "\n",
    "# viewing tables\n",
    "print(my_spark.catalog.listTables())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:29.262956500Z",
     "start_time": "2023-11-20T04:36:19.622986600Z"
    }
   },
   "id": "524104ced377a874"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n",
      "|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n",
      "|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n"
     ]
    }
   ],
   "source": [
    "# Code for part 1.2 (continue)\n",
    "\n",
    "# are you query-ins?\n",
    "\n",
    "# get the query\n",
    "query = \"SELECT * FROM flights LIMIT 10\"\n",
    "\n",
    "# get the first 10 rows of flights\n",
    "flights10 = my_spark.sql(query)\n",
    "\n",
    "# show the results\n",
    "flights10.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:29.627519300Z",
     "start_time": "2023-11-20T04:36:29.265948500Z"
    }
   },
   "id": "6d160478ccbe32e8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  origin dest    N\n",
      "0    SEA  RNO    8\n",
      "1    SEA  DTW   98\n",
      "2    SEA  CLE    2\n",
      "3    SEA  LAX  450\n",
      "4    PDX  SEA  144\n"
     ]
    }
   ],
   "source": [
    "# Code for part 1.2 (continue)\n",
    "\n",
    "# pandafy a spark DataFrame\n",
    "\n",
    "# get the query\n",
    "query = \"SELECT origin, dest, COUNT(*) AS N FROM flights GROUP BY origin, dest\"\n",
    "\n",
    "# run the query\n",
    "flight_counts = my_spark.sql(query)\n",
    "\n",
    "# convert the results to a pandas DataFrame\n",
    "pd_counts = flight_counts.toPandas()\n",
    "print(pd_counts.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:44.267193300Z",
     "start_time": "2023-11-20T04:36:29.631508900Z"
    }
   },
   "id": "e0bff12697cd07d8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\envs\\pyspark\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:479: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='temp', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n",
      "+-------------------+\n",
      "|                  0|\n",
      "+-------------------+\n",
      "|0.06337023132307473|\n",
      "| 0.7772454844841593|\n",
      "| 0.3611821467765055|\n",
      "| 0.7310070835574528|\n",
      "| 0.5382083427812854|\n",
      "|0.31519329604281254|\n",
      "| 0.4251697598541002|\n",
      "| 0.2547094371450006|\n",
      "|0.10345785116274009|\n",
      "| 0.5289974773641084|\n",
      "+-------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code for part 1.2 (continue)\n",
    "\n",
    "# put some spark in your data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create pd_temp\n",
    "pd_temp = pd.DataFrame(np.random.random(10))\n",
    "\n",
    "# create spark_temp_df from pd_temp\n",
    "spark_temp_df = my_spark.createDataFrame(pd_temp)\n",
    "\n",
    "# examine the tables in the catalog\n",
    "print(my_spark.catalog.listTables())\n",
    "\n",
    "# add spark_temp_df to the catalog\n",
    "tableName='temp'\n",
    "spark_temp_df.createOrReplaceTempView(tableName)\n",
    "\n",
    "# examine the tables in the catalog again\n",
    "print(my_spark.catalog.listTables())\n",
    "print(spark_temp_df.show())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:45.799928300Z",
     "start_time": "2023-11-20T04:36:44.268192700Z"
    }
   },
   "id": "e7461cc5153d50d2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "|faa|                name|             lat|              lon| alt| tz|dst|\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "|04G|   Lansdowne Airport|      41.1304722|      -80.6195833|1044| -5|  A|\n",
      "|06A|Moton Field Munic...|      32.4605722|      -85.6800278| 264| -5|  A|\n",
      "|06C| Schaumburg Regional|      41.9893408|      -88.1012428| 801| -6|  A|\n",
      "|06N|     Randall Airport|       41.431912|      -74.3915611| 523| -5|  A|\n",
      "|09J|Jekyll Island Air...|      31.0744722|      -81.4277778|  11| -4|  A|\n",
      "|0A9|Elizabethton Muni...|      36.3712222|      -82.1734167|1593| -4|  A|\n",
      "|0G6|Williams County A...|      41.4673056|      -84.5067778| 730| -5|  A|\n",
      "|0G7|Finger Lakes Regi...|      42.8835647|      -76.7812318| 492| -5|  A|\n",
      "|0P2|Shoestring Aviati...|      39.7948244|      -76.6471914|1000| -5|  U|\n",
      "|0S9|Jefferson County ...|      48.0538086|     -122.8106436| 108| -8|  A|\n",
      "|0W3|Harford County Ai...|      39.5668378|      -76.2024028| 409| -5|  A|\n",
      "|10C|  Galt Field Airport|      42.4028889|      -88.3751111| 875| -6|  U|\n",
      "|17G|Port Bucyrus-Craw...|      40.7815556|      -82.9748056|1003| -5|  A|\n",
      "|19A|Jackson County Ai...|      34.1758638|      -83.5615972| 951| -4|  U|\n",
      "|1A3|Martin Campbell F...|      35.0158056|      -84.3468333|1789| -4|  A|\n",
      "|1B9| Mansfield Municipal|      42.0001331|      -71.1967714| 122| -5|  A|\n",
      "|1C9|Frazier Lake Airpark|54.0133333333333|-124.768333333333| 152| -8|  A|\n",
      "|1CS|Clow Internationa...|      41.6959744|      -88.1292306| 670| -6|  U|\n",
      "|1G3|  Kent State Airport|      41.1513889|      -81.4151111|1134| -4|  A|\n",
      "|1OH|     Fortman Airport|      40.5553253|      -84.3866186| 885| -5|  U|\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "[Table(name='flights', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='temp', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Code for part 1.2 (continue)\n",
    "\n",
    "# dropping the middle man\n",
    "\n",
    "# load the file path\n",
    "file_path = '21_datasets/airports.csv'\n",
    "\n",
    "# read in the airports data\n",
    "airports = my_spark.read.csv(file_path, header=True)\n",
    "\n",
    "# show the data\n",
    "airports.show()\n",
    "print(my_spark.catalog.listTables())\n",
    "\n",
    "# note this new dataframe has not created a table yet, so listTables() does not show it. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:46.148845600Z",
     "start_time": "2023-11-20T04:36:45.801921400Z"
    }
   },
   "id": "2257de26a421ceca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 2. Manipulating data\n",
    "\n",
    "#### Part 2.1 Creating columns\n",
    "\n",
    "* You can create column with *'.withColumn()'* method\n",
    "* It has to be an object of class 'Column'\n",
    "* Updating Spark DataFrame means return a new DataFrame and overwrite the original one\n",
    "* Example: *'df = df.withColumn(\"newCol\", df.oldCol + 1)'*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea5265cb91adbf3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n",
      "|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n",
      "|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n",
      "|2014|   11|  8|    1653|       -2|    1924|       -1|     AS| N323AS|   448|   SEA| LAX|     130|     954|  16|    53|\n",
      "|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA| PHX|     154|    1107|  11|    20|\n",
      "|2014|   10| 30|     811|       21|    1038|       29|     AS| N433AS|   608|   SEA| LAS|     127|     867|   8|    11|\n",
      "|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA| ANC|     183|    1448|  23|    46|\n",
      "|2014|   10| 31|    1314|       89|    1544|      111|     AS| N713AS|   306|   SEA| SFO|     129|     679|  13|    14|\n",
      "|2014|    1| 29|    2009|        3|    2159|        9|     UA| N27205|  1458|   PDX| SFO|      90|     550|  20|     9|\n",
      "|2014|   12| 17|    2015|       50|    2150|       41|     AS| N626AS|   368|   SEA| SMF|      76|     605|  20|    15|\n",
      "|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA| MDW|     216|    1733|  10|    17|\n",
      "|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA| BOS|     290|    2496|  21|    56|\n",
      "|2014|    6|  5|    1733|      -12|    1945|      -10|     OO| N215AG|  3488|   PDX| BUR|     111|     817|  17|    33|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# Code for part 2.1\n",
    "\n",
    "# creating columns\n",
    "\n",
    "# create the DataFrame flights\n",
    "flights = my_spark.table(\"flights\")\n",
    "\n",
    "# show the head and column types\n",
    "flights.show()\n",
    "flights.printSchema()\n",
    "\n",
    "# add duration_hrs\n",
    "flights = flights.withColumn(\"duration_hrs\", flights.air_time / 60)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:46.542843300Z",
     "start_time": "2023-11-20T04:36:46.149842600Z"
    }
   },
   "id": "5e7b75f7a58b0e51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2.2 SQL in s nutshell\n",
    "\n",
    "**Basic understandings of SQL:**\n",
    "* *'SELECT'* command is followed by the columns you want in the table\n",
    "* *'FROM'* command is followed by the name of the table contains these columns\n",
    "* *'WHERE'* command filters rows of tables based on some logical conditions specified\n",
    "*  *'GROUP BY'* command breaks your data into groups and applies a function your *'SELECT'* statement to each group\n",
    "\n",
    "\n",
    "#### Part 2.3 Filtering data\n",
    "\n",
    "* Filtering data with *'.filter()'* method \n",
    "* It is counterpart of SQL's *'WHERE'* clause\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e784a5b2c886d285"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|      duration_hrs|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|               6.0|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|              2.25|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|               3.3|\n",
      "|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA| PHX|     154|    1107|  11|    20| 2.566666666666667|\n",
      "|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA| ANC|     183|    1448|  23|    46|              3.05|\n",
      "|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA| MDW|     216|    1733|  10|    17|               3.6|\n",
      "|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA| BOS|     290|    2496|  21|    56| 4.833333333333333|\n",
      "|2014|    9| 26|     610|       -5|    1523|       65|     US| N127UW|   616|   SEA| PHL|     293|    2378|   6|    10| 4.883333333333334|\n",
      "|2014|   12|  4|     954|       -6|    1348|      -17|     HA| N395HA|    29|   SEA| OGG|     333|    2640|   9|    54|              5.55|\n",
      "|2014|    6|  4|    1115|        0|    1346|       -3|     AS| N461AS|   488|   SEA| SAN|     133|    1050|  11|    15| 2.216666666666667|\n",
      "|2014|    6| 26|    2054|       -1|    2318|       -6|     B6| N590JB|   907|   SEA| ANC|     179|    1448|  20|    54|2.9833333333333334|\n",
      "|2014|    6|  7|    1823|       -7|    2112|      -28|     AS| N512AS|   815|   SEA| LIH|     335|    2701|  18|    23| 5.583333333333333|\n",
      "|2014|    4| 30|     801|        1|    1757|       90|     AS| N407AS|    18|   SEA| MCO|     342|    2554|   8|     1|               5.7|\n",
      "|2014|   11| 29|     905|      155|    1655|      170|     DL| N824DN|  1598|   SEA| ATL|     229|    2182|   9|     5| 3.816666666666667|\n",
      "|2014|    6|  2|    2222|        7|      55|       15|     AS| N402AS|    99|   SEA| ANC|     190|    1448|  22|    22|3.1666666666666665|\n",
      "|2014|   11| 15|    1034|       -6|    1414|      -26|     AS| N589AS|   794|   SEA| ABQ|     139|    1180|  10|    34| 2.316666666666667|\n",
      "|2014|   10| 20|    1328|       -1|    1949|        4|     UA| N68805|  1212|   SEA| IAH|     228|    1874|  13|    28|               3.8|\n",
      "|2014|   12| 16|    1500|        0|    1906|       19|     US| N662AW|   500|   SEA| PHX|     151|    1107|  15|     0|2.5166666666666666|\n",
      "|2014|   11| 19|    1319|       -6|    1821|      -14|     DL| N309US|  2164|   PDX| MSP|     169|    1426|  13|    19| 2.816666666666667|\n",
      "|2014|    5| 21|     515|        0|     757|        0|     US| N172US|   593|   SEA| PHX|     143|    1107|   5|    15|2.3833333333333333|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|      duration_hrs|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|               6.0|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|              2.25|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|               3.3|\n",
      "|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA| PHX|     154|    1107|  11|    20| 2.566666666666667|\n",
      "|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA| ANC|     183|    1448|  23|    46|              3.05|\n",
      "|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA| MDW|     216|    1733|  10|    17|               3.6|\n",
      "|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA| BOS|     290|    2496|  21|    56| 4.833333333333333|\n",
      "|2014|    9| 26|     610|       -5|    1523|       65|     US| N127UW|   616|   SEA| PHL|     293|    2378|   6|    10| 4.883333333333334|\n",
      "|2014|   12|  4|     954|       -6|    1348|      -17|     HA| N395HA|    29|   SEA| OGG|     333|    2640|   9|    54|              5.55|\n",
      "|2014|    6|  4|    1115|        0|    1346|       -3|     AS| N461AS|   488|   SEA| SAN|     133|    1050|  11|    15| 2.216666666666667|\n",
      "|2014|    6| 26|    2054|       -1|    2318|       -6|     B6| N590JB|   907|   SEA| ANC|     179|    1448|  20|    54|2.9833333333333334|\n",
      "|2014|    6|  7|    1823|       -7|    2112|      -28|     AS| N512AS|   815|   SEA| LIH|     335|    2701|  18|    23| 5.583333333333333|\n",
      "|2014|    4| 30|     801|        1|    1757|       90|     AS| N407AS|    18|   SEA| MCO|     342|    2554|   8|     1|               5.7|\n",
      "|2014|   11| 29|     905|      155|    1655|      170|     DL| N824DN|  1598|   SEA| ATL|     229|    2182|   9|     5| 3.816666666666667|\n",
      "|2014|    6|  2|    2222|        7|      55|       15|     AS| N402AS|    99|   SEA| ANC|     190|    1448|  22|    22|3.1666666666666665|\n",
      "|2014|   11| 15|    1034|       -6|    1414|      -26|     AS| N589AS|   794|   SEA| ABQ|     139|    1180|  10|    34| 2.316666666666667|\n",
      "|2014|   10| 20|    1328|       -1|    1949|        4|     UA| N68805|  1212|   SEA| IAH|     228|    1874|  13|    28|               3.8|\n",
      "|2014|   12| 16|    1500|        0|    1906|       19|     US| N662AW|   500|   SEA| PHX|     151|    1107|  15|     0|2.5166666666666666|\n",
      "|2014|   11| 19|    1319|       -6|    1821|      -14|     DL| N309US|  2164|   PDX| MSP|     169|    1426|  13|    19| 2.816666666666667|\n",
      "|2014|    5| 21|     515|        0|     757|        0|     US| N172US|   593|   SEA| PHX|     143|    1107|   5|    15|2.3833333333333333|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Code for part 2.3\n",
    "\n",
    "# filtering data\n",
    "\n",
    "# filter flights by passing a string\n",
    "long_flights1 = flights.filter(\"distance > 1000\")\n",
    "\n",
    "# filter flights by passing a column of boolean values\n",
    "long_flights2 = flights.filter(flights.distance > 1000)\n",
    "\n",
    "# print the data to check if they are equal\n",
    "long_flights1.show()\n",
    "long_flights2.show()\n",
    "\n",
    "# note they are equal."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:46.715035500Z",
     "start_time": "2023-11-20T04:36:46.315450400Z"
    }
   },
   "id": "5fb0e1c893e80e43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2.4 Selecting\n",
    "\n",
    "* Selecting data with *'.select()'* method\n",
    "* You need to specify the columns you select with string or column names\n",
    "* Perform column-wise operation with *'.select()'* method, too\n",
    "* Use *'.alias()'* method to give the selecting column a name\n",
    "* Use *'.selectExpr()'* to take SQL expressions as a string\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8477e33ff829170a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Code for part 2.4\n",
    "\n",
    "# selecting\n",
    "\n",
    "# select the first set of columns\n",
    "selected1 = flights.select(\"tailnum\", \"origin\", \"dest\")\n",
    "\n",
    "# select the second set of columns\n",
    "temp = flights.select(flights.origin, flights.dest, flights.carrier)\n",
    "\n",
    "# define first filter\n",
    "filterA = flights.origin == \"SEA\"\n",
    "\n",
    "# define second filter\n",
    "filterB = flights.dest == \"PDX\"\n",
    "\n",
    "# filter the data, first by filterA, then by filterB\n",
    "selected2 = temp.filter(filterA).filter(filterB)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:46.772854300Z",
     "start_time": "2023-11-20T04:36:46.718026400Z"
    }
   },
   "id": "e7b5e01f21ac049e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Code for part 2.4\n",
    "\n",
    "# selecting (ii)\n",
    "\n",
    "# define avg_speed\n",
    "avg_speed = (flights.distance / (flights.air_time / 60)).alias(\"avg_speed\")\n",
    "\n",
    "# select the correct column\n",
    "speed1 = flights.select(\"origin\", \"dest\", \"tailnum\", avg_speed)\n",
    "\n",
    "# create the same table using a SQL expression\n",
    "speed2 = flights.selectExpr(\"origin\", \"dest\", \"tailnum\", \"distance/ (air_time/60) as avg_speed\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:46.818951600Z",
     "start_time": "2023-11-20T04:36:46.773852200Z"
    }
   },
   "id": "9e4c6f2654731ca5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2.5 Aggregating\n",
    "\n",
    "* Common aggregation methods:\n",
    "    * *'.min()'*\n",
    "    * *'.max()'*\n",
    "    * *'.count()'*\n",
    "    * *'.avg()'*\n",
    "    * *'.sum()'*\n",
    "* They are created by calling the *'.groupBy()'* method\n",
    "* *'.groupBy()'* method can also be called with no arguments\n",
    "* Example: *'df.groupBy().min(\"col\").show()'*\n",
    "* You can also use *'.agg()'* method to pass functions from *'pyspark.sql.functions'* submodule"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e348824cba5a7974"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|min(distance)|\n",
      "+-------------+\n",
      "|          106|\n",
      "+-------------+\n",
      "+-------------+\n",
      "|max(air_time)|\n",
      "+-------------+\n",
      "|          409|\n",
      "+-------------+\n",
      "+------------------+\n",
      "|     avg(air_time)|\n",
      "+------------------+\n",
      "|188.20689655172413|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "| sum(duration_hrs)|\n",
      "+------------------+\n",
      "|25289.600000000126|\n",
      "+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Code for part 2.5\n",
    "\n",
    "# cast \"air_time\" column to numeric\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "flights = flights.withColumn(\"air_time\", flights.air_time.cast(IntegerType()))\n",
    "\n",
    "# find the shortest flight from PDX in terms of distance\n",
    "flights.filter(flights.origin == \"PDX\").groupBy().min(\"distance\").show()\n",
    "\n",
    "# find the longest flight from SEA in terms of air time\n",
    "\n",
    "flights.filter(flights.origin == \"SEA\").groupBy().max(\"air_time\").show()\n",
    "\n",
    "# average duration of Delta flights\n",
    "flights.filter(flights.carrier == \"DL\").filter(flights.origin == \"SEA\").groupBy().avg(\"air_time\").show()\n",
    "\n",
    "# total hours in the air\n",
    "flights.withColumn(\"duration_hrs\", flights.air_time / 60).groupBy().sum(\"duration_hrs\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:48.052395500Z",
     "start_time": "2023-11-20T04:36:46.819948300Z"
    }
   },
   "id": "977d13c55d91dc59"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|tailnum|count|\n",
      "+-------+-----+\n",
      "| N442AS|   38|\n",
      "| N102UW|    2|\n",
      "| N36472|    4|\n",
      "| N38451|    4|\n",
      "| N73283|    4|\n",
      "| N513UA|    2|\n",
      "| N954WN|    5|\n",
      "| N388DA|    3|\n",
      "| N567AA|    1|\n",
      "| N516UA|    2|\n",
      "| N927DN|    1|\n",
      "| N8322X|    1|\n",
      "| N466SW|    1|\n",
      "|  N6700|    1|\n",
      "| N607AS|   45|\n",
      "| N622SW|    4|\n",
      "| N584AS|   31|\n",
      "| N914WN|    4|\n",
      "| N654AW|    2|\n",
      "| N336NW|    1|\n",
      "+-------+-----+\n",
      "+------+------------------+\n",
      "|origin|     avg(air_time)|\n",
      "+------+------------------+\n",
      "|   SEA| 160.4361496051259|\n",
      "|   PDX|137.11543248288737|\n",
      "+------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Code for part 2.5 (continue)\n",
    "\n",
    "# grouping and aggregating (i)\n",
    "\n",
    "# group by tailnum\n",
    "by_plane = flights.groupBy(\"tailnum\")\n",
    "\n",
    "# number of flights each plane made\n",
    "by_plane.count().show()\n",
    "\n",
    "# group by origin\n",
    "by_origin = flights.groupBy(\"origin\")\n",
    "\n",
    "# average duratin of flightss from PDX and SEA\n",
    "by_origin.avg(\"air_time\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:49.079798600Z",
     "start_time": "2023-11-20T04:36:47.942688100Z"
    }
   },
   "id": "d9e38531be82dcc5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------------+\n",
      "|month|dest|     avg(dep_delay)|\n",
      "+-----+----+-------------------+\n",
      "|    4| PHX| 1.6833333333333333|\n",
      "|    1| RDM|             -1.625|\n",
      "|    5| ONT| 3.5555555555555554|\n",
      "|    7| OMA|               -6.5|\n",
      "|    8| MDW|               7.45|\n",
      "|    6| DEN|  5.418181818181818|\n",
      "|    5| IAD|               -4.0|\n",
      "|   12| COS|               -1.0|\n",
      "|   11| ANC|  7.529411764705882|\n",
      "|    5| AUS|              -0.75|\n",
      "|    5| COS| 11.666666666666666|\n",
      "|    2| PSP|                0.6|\n",
      "|    4| ORD|0.14285714285714285|\n",
      "|   10| DFW| 18.176470588235293|\n",
      "|   10| DCA|               -1.5|\n",
      "|    8| JNU|             18.125|\n",
      "|   11| KOA|               -1.0|\n",
      "|   10| OMA|-0.6666666666666666|\n",
      "|    6| ONT|              9.625|\n",
      "|    3| MSP|                3.2|\n",
      "+-----+----+-------------------+\n",
      "+-----+----+------------------+\n",
      "|month|dest| stddev(dep_delay)|\n",
      "+-----+----+------------------+\n",
      "|    4| PHX|15.003380033491737|\n",
      "|    1| RDM| 8.830749846821778|\n",
      "|    5| ONT|18.895178691342874|\n",
      "|    7| OMA|2.1213203435596424|\n",
      "|    8| MDW|14.467659032985843|\n",
      "|    6| DEN|13.536905534420026|\n",
      "|    5| IAD|3.8078865529319543|\n",
      "|   12| COS|1.4142135623730951|\n",
      "|   11| ANC|18.604716401245316|\n",
      "|    5| AUS| 4.031128874149275|\n",
      "|    5| COS| 33.38163167571851|\n",
      "|    2| PSP| 4.878524367060187|\n",
      "|    4| ORD|11.593882803741764|\n",
      "|   10| DFW| 45.53019017606675|\n",
      "|   10| DCA|0.7071067811865476|\n",
      "|    8| JNU| 40.79368823727514|\n",
      "|   11| KOA|1.8708286933869707|\n",
      "|   10| OMA|5.8594652770823155|\n",
      "|    6| ONT| 25.98316762829351|\n",
      "|    3| MSP|21.556779370817555|\n",
      "+-----+----+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Code for part 2.5 (continue)\n",
    "\n",
    "# grouping and aggregating (ii)\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# cast \"dep_delay\" column to numeric\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "flights = flights.withColumn(\"dep_delay\", flights.dep_delay.cast(IntegerType()))\n",
    "\n",
    "# group by month and dest\n",
    "by_month_dest = flights.groupBy(\"month\", \"dest\")\n",
    "\n",
    "# average departure delay by month and destination\n",
    "by_month_dest.avg(\"dep_delay\").show()\n",
    "\n",
    "# standard deviation of departure delay\n",
    "by_month_dest.agg(F.stddev(\"dep_delay\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:50.140079200Z",
     "start_time": "2023-11-20T04:36:48.963112200Z"
    }
   },
   "id": "10ffb9b7d416327d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2.6 Joining\n",
    "\n",
    "* Join will combine two tables along a column that they share, which is called *key*\n",
    "* When you join tables, you are adding all the columns from one table to another table\n",
    "* Example: *'df.join(df2, on='colname', how='leftouter)'*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b52c17255212d27"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA| SFO|     111|     679|  14|    43|\n",
      "|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX| SJC|      83|     569|  17|     5|\n",
      "|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA| BUR|     127|     937|   7|    54|\n",
      "|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX| DEN|     121|     991|  10|    37|\n",
      "|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX| OAK|      90|     543|   8|    47|\n",
      "|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA| SFO|      98|     679|  16|    55|\n",
      "|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA| SAN|     135|    1050|  12|    36|\n",
      "|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA| ORD|     198|    1721|  18|    12|\n",
      "|2014|   11|  8|    1653|       -2|    1924|       -1|     AS| N323AS|   448|   SEA| LAX|     130|     954|  16|    53|\n",
      "|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA| PHX|     154|    1107|  11|    20|\n",
      "|2014|   10| 30|     811|       21|    1038|       29|     AS| N433AS|   608|   SEA| LAS|     127|     867|   8|    11|\n",
      "|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA| ANC|     183|    1448|  23|    46|\n",
      "|2014|   10| 31|    1314|       89|    1544|      111|     AS| N713AS|   306|   SEA| SFO|     129|     679|  13|    14|\n",
      "|2014|    1| 29|    2009|        3|    2159|        9|     UA| N27205|  1458|   PDX| SFO|      90|     550|  20|     9|\n",
      "|2014|   12| 17|    2015|       50|    2150|       41|     AS| N626AS|   368|   SEA| SMF|      76|     605|  20|    15|\n",
      "|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA| MDW|     216|    1733|  10|    17|\n",
      "|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA| BOS|     290|    2496|  21|    56|\n",
      "|2014|    6|  5|    1733|      -12|    1945|      -10|     OO| N215AG|  3488|   PDX| BUR|     111|     817|  17|    33|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "|faa|                name|             lat|              lon| alt| tz|dst|\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "|04G|   Lansdowne Airport|      41.1304722|      -80.6195833|1044| -5|  A|\n",
      "|06A|Moton Field Munic...|      32.4605722|      -85.6800278| 264| -5|  A|\n",
      "|06C| Schaumburg Regional|      41.9893408|      -88.1012428| 801| -6|  A|\n",
      "|06N|     Randall Airport|       41.431912|      -74.3915611| 523| -5|  A|\n",
      "|09J|Jekyll Island Air...|      31.0744722|      -81.4277778|  11| -4|  A|\n",
      "|0A9|Elizabethton Muni...|      36.3712222|      -82.1734167|1593| -4|  A|\n",
      "|0G6|Williams County A...|      41.4673056|      -84.5067778| 730| -5|  A|\n",
      "|0G7|Finger Lakes Regi...|      42.8835647|      -76.7812318| 492| -5|  A|\n",
      "|0P2|Shoestring Aviati...|      39.7948244|      -76.6471914|1000| -5|  U|\n",
      "|0S9|Jefferson County ...|      48.0538086|     -122.8106436| 108| -8|  A|\n",
      "|0W3|Harford County Ai...|      39.5668378|      -76.2024028| 409| -5|  A|\n",
      "|10C|  Galt Field Airport|      42.4028889|      -88.3751111| 875| -6|  U|\n",
      "|17G|Port Bucyrus-Craw...|      40.7815556|      -82.9748056|1003| -5|  A|\n",
      "|19A|Jackson County Ai...|      34.1758638|      -83.5615972| 951| -4|  U|\n",
      "|1A3|Martin Campbell F...|      35.0158056|      -84.3468333|1789| -4|  A|\n",
      "|1B9| Mansfield Municipal|      42.0001331|      -71.1967714| 122| -5|  A|\n",
      "|1C9|Frazier Lake Airpark|54.0133333333333|-124.768333333333| 152| -8|  A|\n",
      "|1CS|Clow Internationa...|      41.6959744|      -88.1292306| 670| -6|  U|\n",
      "|1G3|  Kent State Airport|      41.1513889|      -81.4151111|1134| -4|  A|\n",
      "|1OH|     Fortman Airport|      40.5553253|      -84.3866186| 885| -5|  U|\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "+----+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+--------+--------+----+------+--------------------+---------+-----------+----+---+---+\n",
      "|dest|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|air_time|distance|hour|minute|                name|      lat|        lon| alt| tz|dst|\n",
      "+----+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+--------+--------+----+------+--------------------+---------+-----------+----+---+---+\n",
      "| LAX|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA|     132|     954|   6|    58|    Los Angeles Intl|33.942536|-118.408075| 126| -8|  A|\n",
      "| HNL|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA|     360|    2677|  10|    40|       Honolulu Intl|21.318681|-157.922428|  13|-10|  N|\n",
      "| SFO|2014|    3|  9|    1443|       -2|    1652|        2|     VX| N847VA|   755|   SEA|     111|     679|  14|    43|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "| SJC|2014|    4|  9|    1705|       45|    1839|       34|     WN| N360SW|   344|   PDX|      83|     569|  17|     5|Norman Y Mineta S...|  37.3626|-121.929022|  62| -8|  A|\n",
      "| BUR|2014|    3|  9|     754|       -1|    1015|        1|     AS| N612AS|   522|   SEA|     127|     937|   7|    54|            Bob Hope|34.200667|-118.358667| 778| -8|  A|\n",
      "| DEN|2014|    1| 15|    1037|        7|    1352|        2|     WN| N646SW|    48|   PDX|     121|     991|  10|    37|         Denver Intl|39.861656|-104.673178|5431| -7|  A|\n",
      "| OAK|2014|    7|  2|     847|       42|    1041|       51|     WN| N422WN|  1520|   PDX|      90|     543|   8|    47|Metropolitan Oakl...|37.721278|-122.220722|   9| -8|  A|\n",
      "| SFO|2014|    5| 12|    1655|       -5|    1842|      -18|     VX| N361VA|   755|   SEA|      98|     679|  16|    55|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "| SAN|2014|    4| 19|    1236|       -4|    1508|       -7|     AS| N309AS|   490|   SEA|     135|    1050|  12|    36|      San Diego Intl|32.733556|-117.189667|  17| -8|  A|\n",
      "| ORD|2014|   11| 19|    1812|       -3|    2352|       -4|     AS| N564AS|    26|   SEA|     198|    1721|  18|    12|  Chicago Ohare Intl|41.978603| -87.904842| 668| -6|  A|\n",
      "| LAX|2014|   11|  8|    1653|       -2|    1924|       -1|     AS| N323AS|   448|   SEA|     130|     954|  16|    53|    Los Angeles Intl|33.942536|-118.408075| 126| -8|  A|\n",
      "| PHX|2014|    8|  3|    1120|        0|    1415|        2|     AS| N305AS|   656|   SEA|     154|    1107|  11|    20|Phoenix Sky Harbo...|33.434278|-112.011583|1135| -7|  N|\n",
      "| LAS|2014|   10| 30|     811|       21|    1038|       29|     AS| N433AS|   608|   SEA|     127|     867|   8|    11|      Mc Carran Intl|36.080056| -115.15225|2141| -8|  A|\n",
      "| ANC|2014|   11| 12|    2346|       -4|     217|      -28|     AS| N765AS|   121|   SEA|     183|    1448|  23|    46|Ted Stevens Ancho...|61.174361|-149.996361| 152| -9|  A|\n",
      "| SFO|2014|   10| 31|    1314|       89|    1544|      111|     AS| N713AS|   306|   SEA|     129|     679|  13|    14|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "| SFO|2014|    1| 29|    2009|        3|    2159|        9|     UA| N27205|  1458|   PDX|      90|     550|  20|     9|  San Francisco Intl|37.618972|-122.374889|  13| -8|  A|\n",
      "| SMF|2014|   12| 17|    2015|       50|    2150|       41|     AS| N626AS|   368|   SEA|      76|     605|  20|    15|     Sacramento Intl|38.695417|-121.590778|  27| -8|  A|\n",
      "| MDW|2014|    8| 11|    1017|       -3|    1613|       -7|     WN| N8634A|   827|   SEA|     216|    1733|  10|    17| Chicago Midway Intl|41.785972| -87.752417| 620| -6|  A|\n",
      "| BOS|2014|    1| 13|    2156|       -9|     607|      -15|     AS| N597AS|    24|   SEA|     290|    2496|  21|    56|General Edward La...|42.364347| -71.005181|  19| -5|  A|\n",
      "| BUR|2014|    6|  5|    1733|      -12|    1945|      -10|     OO| N215AG|  3488|   PDX|     111|     817|  17|    33|            Bob Hope|34.200667|-118.358667| 778| -8|  A|\n",
      "+----+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+--------+--------+----+------+--------------------+---------+-----------+----+---+---+\n"
     ]
    }
   ],
   "source": [
    "# Code for part 2.6\n",
    "\n",
    "# joining \n",
    "\n",
    "# get two datasets in the workspace: flights and airports\n",
    "flights = my_spark.read.csv('21_datasets/flights.csv', header=True)\n",
    "airports = my_spark.read.csv('21_datasets/airports.csv', header=True)\n",
    "\n",
    "# examine the data\n",
    "flights.show()\n",
    "airports.show()\n",
    "\n",
    "# rename the \"faa\" column to \"dest\"\n",
    "airports = airports.withColumnRenamed(\"faa\",\"dest\")\n",
    "\n",
    "# join the dataframes\n",
    "flights_with_airports = flights.join(airports, on='dest', how='leftouter')\n",
    "\n",
    "# examine the new DataFrame\n",
    "flights_with_airports.show()\n",
    "\n",
    "# note now we get a bigger dataset when two datasets joined."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:50.921520700Z",
     "start_time": "2023-11-20T04:36:50.142073500Z"
    }
   },
   "id": "9146ab3b7c7401bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 3. Getting Started With Machine Learning Pipelines\n",
    "\n",
    "#### Part 3.1 Machine learning pipelines\n",
    "\n",
    "* We will use *'pyspark.ml'* module\n",
    "* The core of this module are *'Transformer'* and *'Estimator'* class\n",
    "* *'Transformer'* class has a *'.transform()'* method that transforms DataFrame\n",
    "* *'Estimator'* class has a *'.fit()'* method that returns a model object"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c40a02c3f38ec7c0"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Code for part 3.1\n",
    "\n",
    "# join the dataframes\n",
    "\n",
    "# get two dataframes\n",
    "flights = my_spark.read.csv('21_datasets/flights.csv', header=True)\n",
    "planes = my_spark.read.csv('21_datasets/planes.csv', header=True)\n",
    "\n",
    "# rename your column: 'year' to 'plane_year'\n",
    "planes = planes.withColumnRenamed('year', 'plane_year')\n",
    "\n",
    "# join the dataframes\n",
    "model_data = flights.join(planes, on='tailnum', how='leftouter')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:51.203398800Z",
     "start_time": "2023-11-20T04:36:50.924511200Z"
    }
   },
   "id": "aa377b94b27a59dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 3.2 Data types\n",
    "\n",
    "* Spark only handles numeric data, so the data must be either integers or doubles\n",
    "* To remedy this, use the *'.cast()'* method in combination with *'.withColumn()'* method\n",
    "* Example:\n",
    "* *'dataframe = dataframe.withColumn(\"col\", dataframe.col.cast(\"new_type\"))'*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32b65df87d43457b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: string (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      " |-- plane_year: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- engines: string (nullable = true)\n",
      " |-- seats: string (nullable = true)\n",
      " |-- speed: string (nullable = true)\n",
      " |-- engine: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code for part 3.2\n",
    "\n",
    "# string to integer\n",
    "\n",
    "\n",
    "# check column data types\n",
    "print(model_data.printSchema()) # all columns have 'string' data type\n",
    "\n",
    "# cast the columns to integers\n",
    "model_data = model_data.withColumn(\"arr_delay\", model_data.arr_delay.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"air_time\", model_data.air_time.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"month\", model_data.month.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"plane_year\", model_data.plane_year.cast(\"integer\"))\n",
    "\n",
    "# create a new column: 'plane_age'\n",
    "model_data = model_data.withColumn(\"plane_age\", model_data.year - model_data.plane_year)\n",
    "\n",
    "# making a boolean column: 'is_late'\n",
    "model_data = model_data.withColumn(\"is_late\", model_data.arr_delay > 0)\n",
    "\n",
    "# convert it to an integer\n",
    "model_data = model_data.withColumn(\"label\", model_data.is_late.cast(\"integer\"))\n",
    "\n",
    "# remove missing values\n",
    "model_data = model_data.filter(\"arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL and plane_year is not NULL\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:36:51.278689300Z",
     "start_time": "2023-11-20T04:36:51.207389100Z"
    }
   },
   "id": "c18d7e523abba55e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 3.3 Strings and factors\n",
    "\n",
    "* Strings cannot be easily converted to numeric data\n",
    "* PySpark has a *'pyspark.ml.features'* submodule to handle this\n",
    "* It can create 'one-hot vectors' to represent strings information\n",
    "* Encoding steps:\n",
    "1. Create a *'StringIndexer'* class\n",
    "    * *'Estimator'* takes a DataFrame with a column of strings and maps each unique string to a number\n",
    "    * Then returns a *'Transformer'* that takes a DataFrame, attaches the mapping as metadata, and returns a new DataFrame with a numeric column corresponding to the string column\n",
    "2. Encode this numeric column as a one-hot vector using *'OneHotEncoder'*\n",
    "    * Works the same way as *'StringIndexer'*\n",
    "    * Creating an *'Estimator'*\n",
    "    * Then a *'Transformer'*\n",
    "3. All you need to do is to create a *'StringIndexer'* and a *'OneHotEncoder'*, *'Pipeline'* will take care of the rest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec9f1bc679317d53"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Code for part 3.3\n",
    "\n",
    "# carrier and destination: strings to numeric\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "# create a StringIndexer\n",
    "carr_indexer = StringIndexer(inputCol=\"carrier\", outputCol=\"carrier_index\")\n",
    "dest_indexer = StringIndexer(inputCol=\"dest\", outputCol=\"dest_index\")\n",
    "\n",
    "# create a OneHotEncoder\n",
    "carr_encoder = OneHotEncoder(inputCol=\"carrier_index\", outputCol=\"carrier_fact\")\n",
    "dest_encoder = OneHotEncoder(inputCol=\"dest_index\", outputCol=\"dest_fact\")\n",
    "\n",
    "# assembly a vector\n",
    "vec_assembler = VectorAssembler(inputCols=[\"month\", \"air_time\", \"carrier_fact\", \"dest_fact\", \"plane_age\"], outputCol=\"features\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:40:09.331315900Z",
     "start_time": "2023-11-20T04:40:09.168150300Z"
    }
   },
   "id": "e050a2b29d791216"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Code for part 3.3 (continue)\n",
    "\n",
    "# create the pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# make the pipeline\n",
    "flights_pipe = Pipeline(stages=[dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:40:11.830243100Z",
     "start_time": "2023-11-20T04:40:11.825873500Z"
    }
   },
   "id": "82b8eab30d34c7ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 3.4 Test vs. Train\n",
    "\n",
    "* Most important step before modeling: split the data into train set and test set\n",
    "* Test set should not be touched until you think you have a good model\n",
    "* In PySpark, it is important to split the data **after** all the transformations \n",
    "* Use *'.randomSplit()'* method to split the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbee56e98c479580"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Code for part 3.4\n",
    "\n",
    "# transform the model_data\n",
    "piped_data = flights_pipe.fit(model_data).transform(model_data)\n",
    "\n",
    "# split the data\n",
    "training, test = piped_data.randomSplit([.6, .4])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:40:24.678086400Z",
     "start_time": "2023-11-20T04:40:24.036776Z"
    }
   },
   "id": "7435bfb042cbe6e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 4. Model Tuning and Selection\n",
    "\n",
    "#### Part 4.1 What is Logistic Regression?\n",
    "\n",
    "**Logistic Regression:**\n",
    "* Similar to linear regression, but it is not predicting numeric variable, it predicts the probability\n",
    "* You need to assign a cutoff point to these probabilities to classify 'yes' and 'no'\n",
    "* You need to adjust hyperparameters in the model to tune the model for better performance \n",
    "* Use *'pyspark.ml.classification'* class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9a66979b4eedb6e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Code for part 4.1\n",
    "\n",
    "# create the modeler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# create a LR estimator\n",
    "lr = LogisticRegression()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:40:26.778188900Z",
     "start_time": "2023-11-20T04:40:26.771336Z"
    }
   },
   "id": "51f400e93b6982be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 4.2 Cross Validation\n",
    "\n",
    "**Cross Validation:**\n",
    "* Split the training data into a few different partitions\n",
    "* One partition is set aside, the model fits to others\n",
    "* Repeated for each of the partitions\n",
    "* Use *'pyspark.ml.evaluation.BinaryClassificationEvaluator()'* to build evaluator\n",
    "* Use *'pyspark.ml.tuning.ParamGridBuilder()'* to build grid\n",
    "* Use *'crossValidator()'* to perform cross-validation (need to specify evaluator and gird)\n",
    "\n",
    "**Hyperparameters:**\n",
    "* Hyperparameters in the model grid:\n",
    "1. elasticNetParam\n",
    "2. regParam\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba59bd81e3e481f5"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidatorModel_522be99ee996\n"
     ]
    }
   ],
   "source": [
    "# Code for part 4.2\n",
    "\n",
    "# create the evaluator, grid and validator \n",
    "import pyspark.ml.evaluation as evals\n",
    "import pyspark.ml.tuning as tune\n",
    "import numpy as np\n",
    "\n",
    "# create a BinaryClassificationEvaluator\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "\n",
    "# create the parameter grid\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# add the hyperparameter\n",
    "grid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(lr.elasticNetParam, [0,1])\n",
    "\n",
    "# build the grid\n",
    "grid = grid.build()\n",
    "\n",
    "# make the validator\n",
    "# create the CrossValidator (combining earlier steps)\n",
    "cv = tune.CrossValidator(estimator=lr,\n",
    "                         estimatorParamMaps=grid,\n",
    "                         evaluator=evaluator)\n",
    "\n",
    "# fit the model\n",
    "best_lr = cv.fit(training)\n",
    "print(best_lr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:41:13.417753100Z",
     "start_time": "2023-11-20T04:40:29.822042200Z"
    }
   },
   "id": "e299fa01471972e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 4.3 Evaluating binary classifiers\n",
    "\n",
    "* A common classification metric: AUC (Area Under the Curve)\n",
    "* The curve is ROC (Receiver Operating Curve)\n",
    "* The closer the AUC is to one (1), the better the model is"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af7840414f382e93"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6846671249760546\n"
     ]
    }
   ],
   "source": [
    "# Part 4.3 Evaluate the model\n",
    "\n",
    "# use the model to predict the test set\n",
    "test_results = best_lr.transform(test)\n",
    "print(evaluator.evaluate(test_results))\n",
    "\n",
    "# close connection to spark\n",
    "my_spark.stop()\n",
    "\n",
    "# the result is not bad!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T04:41:31.459628800Z",
     "start_time": "2023-11-20T04:41:30.793761200Z"
    }
   },
   "id": "a63f34fac036c95f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the end of this course!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e65bc29ae319d7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
