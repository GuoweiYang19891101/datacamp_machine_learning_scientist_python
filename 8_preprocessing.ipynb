{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing for Machine Learing in Python\n",
    "\n",
    "### CHAPTER 1. Introduction to Data Preprocessing\n",
    "\n",
    "#### 1.1 Introduction to preprocessing\n",
    "\n",
    "* It comes after exploratory data analysis and data cleaning\n",
    "* It is a process of preparing data for modeling\n",
    "* Example:\n",
    "    * transforming categorical features into numerical features (dummy variables)\n",
    "    * removing missing data\n",
    "\n",
    "Why preprocess?\n",
    "* Transform dataset so it's suitable for modeling\n",
    "* Improve model performance\n",
    "* Generate more reliable results\n",
    "\n",
    "Recap: exploring data with pandas\n",
    "* check data with *.head()*\n",
    "* check data information with *.info()*\n",
    "* check summary statistics with *.describe()*\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   opportunity_id  content_id  vol_requests  event_time  \\\n",
      "0            4996       37004            50           0   \n",
      "1            5008       37036             2           0   \n",
      "2            5016       37143            20           0   \n",
      "3            5022       37237           500           0   \n",
      "4            5055       37425            15           0   \n",
      "\n",
      "                                               title  hits  \\\n",
      "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
      "1                                       Web designer    22   \n",
      "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
      "3  Fight global hunger and support women farmers ...    14   \n",
      "4                                      Stop 'N' Swap    31   \n",
      "\n",
      "                                             summary is_priority  category_id  \\\n",
      "0  Building on successful events last summer and ...         NaN          NaN   \n",
      "1             Build a website for an Afghan business         NaN          1.0   \n",
      "2  Please join us and the students from Mott Hall...         NaN          1.0   \n",
      "3  The Oxfam Action Corps is a group of dedicated...         NaN          1.0   \n",
      "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN          4.0   \n",
      "\n",
      "               category_desc  ...     end_date_date    status Latitude  \\\n",
      "0                        NaN  ...      July 30 2011  approved      NaN   \n",
      "1  Strengthening Communities  ...  February 01 2011  approved      NaN   \n",
      "2  Strengthening Communities  ...   January 29 2011  approved      NaN   \n",
      "3  Strengthening Communities  ...     March 31 2012  approved      NaN   \n",
      "4                Environment  ...  February 05 2011  approved      NaN   \n",
      "\n",
      "   Longitude  Community Board Community Council  Census Tract  BIN  BBL NTA  \n",
      "0        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
      "1        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
      "2        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
      "3        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
      "4        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "opportunity_id          0\n",
      "content_id              0\n",
      "vol_requests            0\n",
      "event_time              0\n",
      "title                   0\n",
      "hits                    0\n",
      "summary                 0\n",
      "is_priority           603\n",
      "category_id            48\n",
      "category_desc          48\n",
      "amsl                  665\n",
      "amsl_unit             665\n",
      "org_title               0\n",
      "org_content_id          0\n",
      "addresses_count         0\n",
      "locality               70\n",
      "region                  0\n",
      "postalcode              6\n",
      "primary_loc           665\n",
      "display_url             0\n",
      "recurrence_type         0\n",
      "hours                   0\n",
      "created_date            0\n",
      "last_modified_date      0\n",
      "start_date_date         0\n",
      "end_date_date           0\n",
      "status                  0\n",
      "Latitude              665\n",
      "Longitude             665\n",
      "Community Board       665\n",
      "Community Council     665\n",
      "Census Tract          665\n",
      "BIN                   665\n",
      "BBL                   665\n",
      "NTA                   665\n",
      "dtype: int64\n",
      "(665, 35)\n"
     ]
    }
   ],
   "source": [
    "# exploring missing data\n",
    "import pandas as pd\n",
    "\n",
    "volunteer = pd.read_csv('8_datasets/volunteer.csv')\n",
    "print(volunteer.head())\n",
    "print(volunteer.isna().sum())\n",
    "print(volunteer.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 33)\n"
     ]
    }
   ],
   "source": [
    "# dropping missing data\n",
    "# drop 'Latitude' and 'Longitude' columns\n",
    "volunteer_cols = volunteer.drop(['Latitude', 'Longitude'], axis=1)\n",
    "\n",
    "# drop rows with missing 'category_desc' column\n",
    "volunteer_subset = volunteer_cols.dropna(subset=['category_desc'])\n",
    "\n",
    "print(volunteer_subset.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Working with data types\n",
    "\n",
    "Common data types:\n",
    "* 'object': string/mixed types\n",
    "* 'int64': integer\n",
    "* 'float64': float\n",
    "* 'datetime64': dates and times\n",
    "\n",
    "Converting column types:\n",
    "* *astype()* method to specify data type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 665 entries, 0 to 664\n",
      "Data columns (total 35 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   opportunity_id      665 non-null    int64  \n",
      " 1   content_id          665 non-null    int64  \n",
      " 2   vol_requests        665 non-null    int64  \n",
      " 3   event_time          665 non-null    int64  \n",
      " 4   title               665 non-null    object \n",
      " 5   hits                665 non-null    int64  \n",
      " 6   summary             665 non-null    object \n",
      " 7   is_priority         62 non-null     object \n",
      " 8   category_id         617 non-null    float64\n",
      " 9   category_desc       617 non-null    object \n",
      " 10  amsl                0 non-null      float64\n",
      " 11  amsl_unit           0 non-null      float64\n",
      " 12  org_title           665 non-null    object \n",
      " 13  org_content_id      665 non-null    int64  \n",
      " 14  addresses_count     665 non-null    int64  \n",
      " 15  locality            595 non-null    object \n",
      " 16  region              665 non-null    object \n",
      " 17  postalcode          659 non-null    float64\n",
      " 18  primary_loc         0 non-null      float64\n",
      " 19  display_url         665 non-null    object \n",
      " 20  recurrence_type     665 non-null    object \n",
      " 21  hours               665 non-null    int64  \n",
      " 22  created_date        665 non-null    object \n",
      " 23  last_modified_date  665 non-null    object \n",
      " 24  start_date_date     665 non-null    object \n",
      " 25  end_date_date       665 non-null    object \n",
      " 26  status              665 non-null    object \n",
      " 27  Latitude            0 non-null      float64\n",
      " 28  Longitude           0 non-null      float64\n",
      " 29  Community Board     0 non-null      float64\n",
      " 30  Community Council   0 non-null      float64\n",
      " 31  Census Tract        0 non-null      float64\n",
      " 32  BIN                 0 non-null      float64\n",
      " 33  BBL                 0 non-null      float64\n",
      " 34  NTA                 0 non-null      float64\n",
      "dtypes: float64(13), int64(8), object(14)\n",
      "memory usage: 182.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# exploring data types\n",
    "import pandas as pd\n",
    "volunteer = pd.read_csv('8_datasets/volunteer.csv')\n",
    "print(volunteer.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    737\n",
      "1     22\n",
      "2     62\n",
      "3     14\n",
      "4     31\n",
      "Name: hits, dtype: int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# converting a column type -> 'hits'\n",
    "print(volunteer['hits'].head())\n",
    "volunteer['hits'] = volunteer['hits'].astype('int64')\n",
    "print(volunteer['hits'].dtypes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Training and test sets\n",
    "\n",
    "Why split?\n",
    "* Reduces over-fitting\n",
    "* Evaluate performance on a holdout set\n",
    "* *train_test_split()* method to split\n",
    "* *stratify* parameter to avoid class imbalance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    307\n",
      "Helping Neighbors in Need    119\n",
      "Education                     92\n",
      "Health                        52\n",
      "Environment                   32\n",
      "Emergency Preparedness        15\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class imbalance\n",
    "import pandas as pd\n",
    "volunteer = pd.read_csv('8_datasets/volunteer.csv')\n",
    "\n",
    "# check class distribution\n",
    "print(volunteer['category_desc'].value_counts())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opportunity_id         0\n",
      "content_id             0\n",
      "vol_requests           0\n",
      "event_time             0\n",
      "title                  0\n",
      "hits                   0\n",
      "summary                0\n",
      "category_id           48\n",
      "category_desc         48\n",
      "org_title              0\n",
      "org_content_id         0\n",
      "addresses_count        0\n",
      "region                 0\n",
      "postalcode             6\n",
      "display_url            0\n",
      "recurrence_type        0\n",
      "hours                  0\n",
      "created_date           0\n",
      "last_modified_date     0\n",
      "start_date_date        0\n",
      "end_date_date          0\n",
      "status                 0\n",
      "dtype: int64\n",
      "opportunity_id        0\n",
      "content_id            0\n",
      "vol_requests          0\n",
      "event_time            0\n",
      "title                 0\n",
      "hits                  0\n",
      "summary               0\n",
      "category_id           0\n",
      "category_desc         0\n",
      "org_title             0\n",
      "org_content_id        0\n",
      "addresses_count       0\n",
      "region                0\n",
      "postalcode            0\n",
      "display_url           0\n",
      "recurrence_type       0\n",
      "hours                 0\n",
      "created_date          0\n",
      "last_modified_date    0\n",
      "start_date_date       0\n",
      "end_date_date         0\n",
      "status                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop missing value columns\n",
    "volunteer = volunteer.dropna(axis=1, thresh=600)\n",
    "\n",
    "# check missing values\n",
    "print(volunteer.isna().sum())\n",
    "\n",
    "# fill in these missing values in these three columns:\n",
    "volunteer['category_id'] = volunteer['category_id'].astype('object')\n",
    "volunteer['category_id'] = volunteer['category_id'].fillna('bfill')\n",
    "\n",
    "volunteer['category_desc'] = volunteer['category_desc'].astype('object')\n",
    "volunteer['category_desc'] = volunteer['category_desc'].fillna('bfill')\n",
    "\n",
    "volunteer['postalcode'] = volunteer['postalcode'].astype('object')\n",
    "volunteer['postalcode'] = volunteer['postalcode'].fillna('bfill')\n",
    "# check missing values again\n",
    "print(volunteer.isna().sum())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    245\n",
      "Helping Neighbors in Need     95\n",
      "Education                     74\n",
      "Health                        42\n",
      "bfill                         38\n",
      "Environment                   26\n",
      "Emergency Preparedness        12\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into X and y\n",
    "X = volunteer.drop(['category_desc'], axis=1)\n",
    "y = volunteer[['category_desc']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(y_train['category_desc'].value_counts())\n",
    "\n",
    "# the training set class distribution is the same as original dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 2. Standardizing Data\n",
    "\n",
    "#### 2.1 Standardization\n",
    "\n",
    "* It transforms *continuous data* to look *normally distributed*\n",
    "* 'scikit-learn' models assume normally distributed data\n",
    "* Using non-normal training data can lead to bias\n",
    "\n",
    "Two methods of standardization:\n",
    "1. Log normalization\n",
    "2. Scaling\n",
    "\n",
    "When to standardize?\n",
    "* When working with models that use a linear distance metric or operate in a linear space (e.g: k-nearest neighbors, linear regression, k-means clustering)\n",
    "* When dataset features have *high variance*\n",
    "* When dataset features are on *different scales*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# modeling without normalizing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "wine = pd.read_csv('8_datasets/wine.csv')\n",
    "\n",
    "# split data\n",
    "X = wine.drop('Type', axis=1)\n",
    "y = wine['Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# fit k-neearest neighbors model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(knn.score(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result is not very good, let's see how we can improve model performance by standardization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Log normalization\n",
    "\n",
    "* It is useful when features have high variance\n",
    "* It applies logarithm transformation to the values\n",
    "* It takes the natural log of each number:\n",
    "$$ e( \\approx 2.718) $$\n",
    "* It captures relative changes, the magnitude of change, and keeps everything positive\n",
    "* Use *log()* function from 'numpy' library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Type     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
      "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
      "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
      "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
      "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
      "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
      "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
      "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
      "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
      "\n",
      "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
      "count  178.000000     178.000000  178.000000            178.000000   \n",
      "mean    99.741573       2.295112    2.029270              0.361854   \n",
      "std     14.282484       0.625851    0.998859              0.124453   \n",
      "min     70.000000       0.980000    0.340000              0.130000   \n",
      "25%     88.000000       1.742500    1.205000              0.270000   \n",
      "50%     98.000000       2.355000    2.135000              0.340000   \n",
      "75%    107.000000       2.800000    2.875000              0.437500   \n",
      "max    162.000000       3.880000    5.080000              0.660000   \n",
      "\n",
      "       Proanthocyanins  Color intensity         Hue  \\\n",
      "count       178.000000       178.000000  178.000000   \n",
      "mean          1.590899         5.058090    0.957449   \n",
      "std           0.572359         2.318286    0.228572   \n",
      "min           0.410000         1.280000    0.480000   \n",
      "25%           1.250000         3.220000    0.782500   \n",
      "50%           1.555000         4.690000    0.965000   \n",
      "75%           1.950000         6.200000    1.120000   \n",
      "max           3.580000        13.000000    1.710000   \n",
      "\n",
      "       OD280/OD315 of diluted wines      Proline  \n",
      "count                    178.000000   178.000000  \n",
      "mean                       2.611685   746.893258  \n",
      "std                        0.709990   314.907474  \n",
      "min                        1.270000   278.000000  \n",
      "25%                        1.937500   500.500000  \n",
      "50%                        2.780000   673.500000  \n",
      "75%                        3.170000   985.000000  \n",
      "max                        4.000000  1680.000000  \n"
     ]
    }
   ],
   "source": [
    "# checking the variance\n",
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('8_datasets/wine.csv')\n",
    "print(wine.describe())\n",
    "# column 'Proline' has extremely high variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99166.71735542436\n",
      "0.17231366191842012\n"
     ]
    }
   ],
   "source": [
    "# log normlization in Python\n",
    "import numpy as np\n",
    "\n",
    "# print variance of column 'Proline'\n",
    "print(wine['Proline'].var())\n",
    "\n",
    "# get log normalization variance\n",
    "wine['Proline_log'] = np.log(wine['Proline'])\n",
    "print(wine['Proline_log'].var())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Scaling data for feature comparision\n",
    "\n",
    "* It is useful when features are on different scales\n",
    "* Model with linear characteristics\n",
    "* It centers feature around 0 and transform to variance of 1\n",
    "* It transforms to approximately normal distribution\n",
    "* Use *StandardScaler()* method from 'sklearn' library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Type                          178 non-null    int64  \n",
      " 1   Alcohol                       178 non-null    float64\n",
      " 2   Malic acid                    178 non-null    float64\n",
      " 3   Ash                           178 non-null    float64\n",
      " 4   Alcalinity of ash             178 non-null    float64\n",
      " 5   Magnesium                     178 non-null    int64  \n",
      " 6   Total phenols                 178 non-null    float64\n",
      " 7   Flavanoids                    178 non-null    float64\n",
      " 8   Nonflavanoid phenols          178 non-null    float64\n",
      " 9   Proanthocyanins               178 non-null    float64\n",
      " 10  Color intensity               178 non-null    float64\n",
      " 11  Hue                           178 non-null    float64\n",
      " 12  OD280/OD315 of diluted wines  178 non-null    float64\n",
      " 13  Proline                       178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n",
      "None\n",
      "             Type     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
      "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
      "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
      "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
      "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
      "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
      "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
      "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
      "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
      "\n",
      "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
      "count  178.000000     178.000000  178.000000            178.000000   \n",
      "mean    99.741573       2.295112    2.029270              0.361854   \n",
      "std     14.282484       0.625851    0.998859              0.124453   \n",
      "min     70.000000       0.980000    0.340000              0.130000   \n",
      "25%     88.000000       1.742500    1.205000              0.270000   \n",
      "50%     98.000000       2.355000    2.135000              0.340000   \n",
      "75%    107.000000       2.800000    2.875000              0.437500   \n",
      "max    162.000000       3.880000    5.080000              0.660000   \n",
      "\n",
      "       Proanthocyanins  Color intensity         Hue  \\\n",
      "count       178.000000       178.000000  178.000000   \n",
      "mean          1.590899         5.058090    0.957449   \n",
      "std           0.572359         2.318286    0.228572   \n",
      "min           0.410000         1.280000    0.480000   \n",
      "25%           1.250000         3.220000    0.782500   \n",
      "50%           1.555000         4.690000    0.965000   \n",
      "75%           1.950000         6.200000    1.120000   \n",
      "max           3.580000        13.000000    1.710000   \n",
      "\n",
      "       OD280/OD315 of diluted wines      Proline  \n",
      "count                    178.000000   178.000000  \n",
      "mean                       2.611685   746.893258  \n",
      "std                        0.709990   314.907474  \n",
      "min                        1.270000   278.000000  \n",
      "25%                        1.937500   500.500000  \n",
      "50%                        2.780000   673.500000  \n",
      "75%                        3.170000   985.000000  \n",
      "max                        4.000000  1680.000000  \n"
     ]
    }
   ],
   "source": [
    "# scaling data\n",
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('8_datasets/wine.csv')\n",
    "print(wine.info())\n",
    "\n",
    "# check columns statistics\n",
    "print(wine.describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# standardizing columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# get subset\n",
    "cols=['Ash', 'Alcalinity of ash', 'Magnesium']\n",
    "wine_subset = wine[cols]\n",
    "\n",
    "# apply scaler\n",
    "wine_subset_scaled = scaler.fit_transform(wine_subset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Standardized data and modeling\n",
    "\n",
    "Recall:\n",
    "* k-nearest neighbors is a model classifies data based on its distance on training set data\n",
    "* New data is assigned a label based on the class that majority of surrounding data points belong to\n",
    "* It is important to **split the data before preprocessing**, so none of the test data is used to train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN on unscaled data:\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# KNN on non-scaled data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "wine = pd.read_csv('8_datasets/wine.csv')\n",
    "\n",
    "# split the dataset\n",
    "X = wine.drop('Type', axis=1)\n",
    "y = wine['Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# create KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# get score\n",
    "print('KNN on unscaled data:')\n",
    "print(knn.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN on scaled data:\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# KNN on scaled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# use the same dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# create model\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# get score\n",
    "print('KNN on scaled data:')\n",
    "print(knn.score(X_test_scaled, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a significant improvement on model performance after scaling data!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 3. Feature Engineering\n",
    "\n",
    "#### 3.1 Feature Engineering\n",
    "\n",
    "*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 Encoding categorial variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3 Engineering numerical features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.4 Engineering text features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
