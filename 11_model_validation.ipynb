{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Model Validation\n",
    "\n",
    "**Course structure:**\n",
    "* Chapter 1: Basic modeling in scikit-learn\n",
    "* Chapter 2: Validation basics\n",
    "* Chapter 3: Cross Validation\n",
    "* Chapter 4: Selecting the best model with Hyperparameter tuning\n",
    "\n",
    "### CHAPTER 1. Basic modeling in scikit-learn\n",
    "\n",
    "#### 1.1 Introduction to model validation\n",
    "\n",
    "**Model validation consists of:**\n",
    "* Ensuring your model performs as expected on new data\n",
    "* Testing model performance on holdout datasets\n",
    "* Selecting the best model, parameters, and accuracy metrics\n",
    "* Achieving the best accuracy for the data given\n",
    "\n",
    "**Scikit-learn basic modeling review:**\n",
    "* Creating a model by specifying the model type and parameters\n",
    "* Fitting the model to training dataset\n",
    "* Generating predictions for test dataset\n",
    "    * Looking at accuracy metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error on seen data: 3.36\n",
      "Model error on unseen data: 11.05\n"
     ]
    }
   ],
   "source": [
    "# seen vs. unseen data\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# get data and split into train and test\n",
    "candy_df = pd.read_csv('11_datasets/candy-data.csv')\n",
    "\n",
    "candy_df = candy_df.drop(['competitorname'], axis=1)\n",
    "X = candy_df.iloc[:, :-1]\n",
    "y = candy_df.iloc[:, -1]\n",
    "X_train, X_test = X.iloc[:50], X.iloc[50:]\n",
    "y_train, y_test = y.iloc[:50], y.iloc[50:]\n",
    "\n",
    "# create model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# train/test errors (metrics)\n",
    "train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
    "test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
    "print('Model error on seen data: {0:.2f}'.format(train_error))\n",
    "print('Model error on unseen data: {0:.2f}'.format(test_error))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Regression models\n",
    "\n",
    "**Two types of predictive models:**\n",
    "1. Regression models (built for continuous variables)\n",
    "2. Classification models (built for categorical variables)\n",
    "\n",
    "* This course will ONLY focus on **Random Forest** models\n",
    "* Decision tree is the basics of random forest models, it splits data until only a few or even a single observations remains\n",
    "* Random forest regression models generate a bunch of different decision trees\n",
    "* Use the mean prediction of these trees as final value\n",
    "\n",
    "**Random Forest parameters:**\n",
    "1. *'n_estimator'*: the number of trees in the forest\n",
    "2. *'max_depth'*: the maximum depth of the trees\n",
    "3. *'random_state'*: random seed\n",
    "and so on...\n",
    "\n",
    "**Feature Importance:**\n",
    "* One feature for random forest models is feature importance\n",
    "* It shows how important different features of the data were in the model\n",
    "* Use *'.feature_importances_'* attribute"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate: 0.61\n",
      "fruity: 0.02\n",
      "caramel: 0.02\n",
      "peanutyalmondy: 0.01\n",
      "nougat: 0.02\n",
      "crispedricewafer: 0.03\n",
      "hard: 0.00\n",
      "bar: 0.00\n",
      "pluribus: 0.02\n",
      "sugarpercent: 0.15\n",
      "pricepercent: 0.11\n"
     ]
    }
   ],
   "source": [
    "# set parameters and fit a model\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# use the same dataset as above exercise\n",
    "# get data and split into train and test\n",
    "candy_df = pd.read_csv('11_datasets/candy-data.csv')\n",
    "\n",
    "candy_df = candy_df.drop(['competitorname'], axis=1)\n",
    "X = candy_df.iloc[:, :-1]\n",
    "y = candy_df.iloc[:, -1]\n",
    "X_train, X_test = X.iloc[:50], X.iloc[50:]\n",
    "y_train, y_test = y.iloc[:50], y.iloc[50:]\n",
    "\n",
    "# create a model with parameters\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.n_estimators = 100\n",
    "rfr.max_depth = 6\n",
    "rfr.random_state = 1111\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# print feature importances\n",
    "for i, item in enumerate(rfr.feature_importances_):\n",
    "    print('{0:s}: {1:.2f}'.format(X_train.columns[i], item))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Classification models\n",
    "\n",
    "* These models have **categorical responses:**\n",
    "    * Newborn's hair color\n",
    "    * Winner of a basketball game\n",
    "    * Genre of the next song on the radio\n",
    "\n",
    "**Interesting methods in classification models:**\n",
    "* Besides *'.predict()'* method to **predict class**, classification models can also use *'.predict_proba()'* method to **predict probabilities**\n",
    "* *'get_params()'* method is used to review which **parameters** went into a model\n",
    "* *'.score()'* method is a quick way to look at the **overall accuracy** of the classification model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    563\n",
      "0    204\n",
      "dtype: int64\n",
      "The first predicted probabilities are: [0.26524423 0.73475577]\n",
      "0.817470664928292\n"
     ]
    }
   ],
   "source": [
    "# classification predictions\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get data\n",
    "tic_tac_toe = pd.read_csv('11_datasets/tic-tac-toe.csv')\n",
    "# print(tic_tac_toe.shape)\n",
    "X = tic_tac_toe.drop(['Class'], axis=1)\n",
    "y = tic_tac_toe['Class']\n",
    "\n",
    "# convert categorical values to numbers\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# split X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=1111)\n",
    "\n",
    "# create a model\n",
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "classification_predictions = rfc.predict(X_test)\n",
    "probability_predictions = rfc.predict_proba(X_test)\n",
    "print(pd.Series(classification_predictions).value_counts())\n",
    "print('The first predicted probabilities are: {}'.format(probability_predictions[0]))\n",
    "\n",
    "# get accuracy score\n",
    "print(rfc.score(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=6, n_estimators=50, random_state=1111)\n",
      "The random state is: 1111\n",
      "Printing the parameters dictionary: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# reusing model parameters\n",
    "# print the classification model\n",
    "print(rfc)\n",
    "\n",
    "# print the model's random state parameter\n",
    "print('The random state is: {}'.format(rfc.random_state))\n",
    "\n",
    "# print all parameters\n",
    "print('Printing the parameters dictionary: {}'. format(rfc.get_params()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 2. Validation Basics\n",
    "\n",
    "#### 2.1 Creating train, test and validation datasets\n",
    "\n",
    "**Traditional dataset split:**\n",
    "* Seen data (used for training)\n",
    "* Unseen data (unavailable for training, used to assess model performance)\n",
    "* Use *'train_test_split()'* method to achieve this\n",
    "\n",
    "**Hyper-parameter tuning dataset split (second validation set):**\n",
    "* Training: used for training\n",
    "* Validation: used to assess the model's performance when using different parameter values\n",
    "* Testing: test new unseen data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862, 27)\n",
      "(96, 27)\n"
     ]
    }
   ],
   "source": [
    "# create one holdout set\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get data\n",
    "tic_tac_toe = pd.read_csv('11_datasets/tic-tac-toe.csv')\n",
    "X = tic_tac_toe.drop(['Class'], axis=1)\n",
    "y = tic_tac_toe['Class']\n",
    "\n",
    "# convert categorical values to numbers\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# create training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574,)\n",
      "(192,)\n",
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "# create two holdout sets\n",
    "# use same dataset as above exercise\n",
    "\n",
    "# create temp training and testing dataset\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "# create final training and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Accuracy metrics: regression models\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "* Simplest and most intuitive metic\n",
    "* Treats all points equally\n",
    "* Not sensitive to outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.Image(\"Images/11_mae.PNG\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Mean Squared Error (MSE)**:\n",
    "* Most widely used regression metric\n",
    "* Allows outlier errors to contribute more to overall error\n",
    "\n",
    "**NOTE:**\n",
    "* Sometimes, we want to know a model's accuracy for a specific subset, such as on only chocolate candies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.Image(\"Images/11_mse.PNG\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 5.9\n",
      "Using scikit-learn, the error is 5.9\n"
     ]
    }
   ],
   "source": [
    "# mean absolute error\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# get manual data\n",
    "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20, 67, 61,\n",
    "                   55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
    "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15, 72, 58,\n",
    "                        60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])\n",
    "\n",
    "# manually calculate the MAE\n",
    "n = len(predictions)\n",
    "mae_one = sum(abs(y_test - predictions)) / n\n",
    "print('With a manual calculation, the error is {}'.format(mae_one))\n",
    "\n",
    "# use scikit-learn to calculate the MAE\n",
    "mae_two = mae(y_test, predictions)\n",
    "print('Using scikit-learn, the error is {}'.format(mae_two))\n",
    "\n",
    "# note two results are the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 49.1\n",
      "Using scikit-learn, the error is 49.1\n"
     ]
    }
   ],
   "source": [
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# manually calculate the MSE\n",
    "n = len(predictions)\n",
    "mse_one = sum((y_test - predictions)**2) / n\n",
    "print('With a manual calculation, the error is {}'.format(mse_one))\n",
    "\n",
    "# use the scikit-learn to calculate MSE\n",
    "mse_two = mse(y_test, predictions)\n",
    "print('Using scikit-learn, the error is {}'.format(mse_two))\n",
    "\n",
    "# note two results are the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# performance on data subsets\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Performance on data subsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Accuracy metrics: classification models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.5 The bias-variance tradeoff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CHAPTER 3. Cross Validation\n",
    "\n",
    "#### 3.1 The problem with holdout sets\n",
    "\n",
    "*"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
